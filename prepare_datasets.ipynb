{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoReload `.py` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определим необходимые константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sentencepiece as spm\n",
    "from common.utils import (\n",
    "    replace_numbers,\n",
    "    create_sentencepiece_dataset\n",
    ")\n",
    "\n",
    "\n",
    "CODE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(CODE_DIR, 'data')\n",
    "CONLL2003_DIR = os.path.join(DATA_DIR, 'conll2003')\n",
    "WNUT17_DIR = os.path.join(DATA_DIR, 'wnut17')\n",
    "TOKENS_CONLL2003 = 30000\n",
    "TOKENS_WNUT17 = 20000\n",
    "TRAIN_SENTENCEPIECE_STRING = '--input={input_data} --model_prefix={prefix} --vocab_size={vocab_size} --model_type=bpe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заменим все цифры на это слово [NUM]\n",
    "`В загруженных на Github данных это уже было сделано, поэтому прогонять этот код необязательно`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in [\n",
    "    os.path.join(CONLL2003_DIR, 'conll2003.train'),\n",
    "    os.path.join(CONLL2003_DIR, 'conll2003.test'),\n",
    "    os.path.join(CONLL2003_DIR, 'conll2003.valid'),\n",
    "    os.path.join(WNUT17_DIR, 'wnut17conll.train'),\n",
    "    os.path.join(WNUT17_DIR, 'wnut17conll.test')\n",
    "]:\n",
    "    txt = replace_numbers(path)\n",
    "    with open(path, 'w', encoding='utf-8') as file:\n",
    "        file.write(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Составим датасет для SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    os.path.join(CONLL2003_DIR, 'conll2003.train'),\n",
    "    os.path.join(CONLL2003_DIR, 'conll2003.test'),\n",
    "    os.path.join(CONLL2003_DIR, 'conll2003.valid'),\n",
    "    os.path.join(WNUT17_DIR, 'wnut17conll.train'),\n",
    "    os.path.join(WNUT17_DIR, 'wnut17conll.test')\n",
    "]\n",
    "save_paths = [f'{x}_sp' for x in paths]\n",
    "for path, save_path in zip(paths, save_paths):\n",
    "    create_sentencepiece_dataset(path, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь объединим `conll2003.train_sp`, `conll2003.test_sp` и `conll2003.valid_sp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./data/conll2003/conll2003.train_sp ./data/conll2003/conll2003_sp_dataset.txt\n",
    "\n",
    "!cat ./data/conll2003/conll2003.test_sp >> ./data/conll2003/conll2003_sp_dataset.txt\n",
    "!cat ./data/conll2003/conll2003.valid_sp >> ./data/conll2003/conll2003_sp_dataset.txt\n",
    "\n",
    "!rm ./data/conll2003/conll2003.train_sp ./data/conll2003/conll2003.test_sp ./data/conll2003/conll2003.valid_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.Train(\n",
    "    TRAIN_SENTENCEPIECE_STRING.format(\n",
    "        input_data=os.path.join(CONLL2003_DIR, 'conll2003_sp_dataset.txt'),\n",
    "        prefix='conll2003_sp',\n",
    "        vocab_size=TOKENS_CONLL2003\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2020-04-25 21:55:47.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mProcessing dataset at path: ./data/conll2003/conll2003.train\u001b[0m\n",
      "Processing lines: 28082it [00:02, 13817.41it/s]\n",
      "\u001b[32m2020-04-25 21:55:49.960\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m27\u001b[0m - \u001b[32m\u001b[1mSuccessfully processed dataset and started saving at path: ./data/conll2003/conll2003.train.spm\u001b[0m\n",
      "\u001b[32m2020-04-25 21:55:49.976\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m31\u001b[0m - \u001b[32m\u001b[1mSaved dataset\u001b[0m\n",
      "\u001b[32m2020-04-25 21:55:49.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mProcessing dataset at path: ./data/conll2003/conll2003.test\u001b[0m\n",
      "Processing lines: 6500it [00:00, 12878.53it/s]\n",
      "\u001b[32m2020-04-25 21:55:50.484\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m27\u001b[0m - \u001b[32m\u001b[1mSuccessfully processed dataset and started saving at path: ./data/conll2003/conll2003.test.spm\u001b[0m\n",
      "\u001b[32m2020-04-25 21:55:50.485\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m31\u001b[0m - \u001b[32m\u001b[1mSaved dataset\u001b[0m\n",
      "\u001b[32m2020-04-25 21:55:50.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mProcessing dataset at path: ./data/conll2003/conll2003.valid\u001b[0m\n",
      "Processing lines: 6906it [00:00, 16355.42it/s]\n",
      "\u001b[32m2020-04-25 21:55:50.909\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m27\u001b[0m - \u001b[32m\u001b[1mSuccessfully processed dataset and started saving at path: ./data/conll2003/conll2003.valid.spm\u001b[0m\n",
      "\u001b[32m2020-04-25 21:55:50.911\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m31\u001b[0m - \u001b[32m\u001b[1mSaved dataset\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python common/apply_sentencepiece.py \\\n",
    "    --dataset_paths ./data/conll2003/conll2003.train ./data/conll2003/conll2003.test ./data/conll2003/conll2003.valid \\\n",
    "    --sentencepiece_model_path conll2003_sp.model \\\n",
    "    --tagging_format IOB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь объединим `wnut17conll.train_sp`, `wnut17conll.test_sp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp ./data/wnut17/wnut17conll.train_sp ./data/wnut17/wnut17conll_sp_dataset.txt\n",
    "\n",
    "!cat ./data/wnut17/wnut17conll.test_sp >> ./data/wnut17/wnut17conll_sp_dataset.txt\n",
    "\n",
    "!rm ./data/wnut17/wnut17conll.train_sp ./data/wnut17/wnut17conll.test_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm.SentencePieceTrainer.Train(\n",
    "    TRAIN_SENTENCEPIECE_STRING.format(\n",
    "        input_data=os.path.join(WNUT17_DIR, 'wnut17conll_sp_dataset.txt'),\n",
    "        prefix='wnut17conll_sp',\n",
    "        vocab_size=TOKENS_WNUT17\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2020-04-25 21:55:54.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mProcessing dataset at path: ./data/wnut17/wnut17conll.train\u001b[0m\n",
      "Processing lines: 6788it [00:00, 12237.62it/s]\n",
      "\u001b[32m2020-04-25 21:55:54.838\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m27\u001b[0m - \u001b[32m\u001b[1mSuccessfully processed dataset and started saving at path: ./data/wnut17/wnut17conll.train.spm\u001b[0m\n",
      "\u001b[32m2020-04-25 21:55:54.840\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m31\u001b[0m - \u001b[32m\u001b[1mSaved dataset\u001b[0m\n",
      "\u001b[32m2020-04-25 21:55:54.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mProcessing dataset at path: ./data/wnut17/wnut17conll.test\u001b[0m\n",
      "Processing lines: 2574it [00:00, 10764.92it/s]\n",
      "\u001b[32m2020-04-25 21:55:55.080\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m27\u001b[0m - \u001b[32m\u001b[1mSuccessfully processed dataset and started saving at path: ./data/wnut17/wnut17conll.test.spm\u001b[0m\n",
      "\u001b[32m2020-04-25 21:55:55.081\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m31\u001b[0m - \u001b[32m\u001b[1mSaved dataset\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python common/apply_sentencepiece.py \\\n",
    "    --dataset_paths ./data/wnut17/wnut17conll.train ./data/wnut17/wnut17conll.test \\\n",
    "    --sentencepiece_model_path wnut17conll_sp.model \\\n",
    "    --tagging_format BIO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kursach_venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
